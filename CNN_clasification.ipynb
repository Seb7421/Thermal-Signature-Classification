{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\">Fine-Tuning a Convolutional Neural Network for Infrared Drone Image Classification in Wildlife Conservation</p>\n",
    "\n",
    "<p style=\"text-align: center;\">Abstract: </p>\n",
    "<p style=\"text-align: center;\"> This tutorial demonstrates how to effectively fine tune and evaluate a CNN model using the birdsai dataset of night time infrared images from drones in Souther Africa. The tutorial starts with how to best set up the data for the fine tuning, then the process of fine-tuning and evaluating the CNN model. The resulting model is one that can be used to classify frames captured by drones at night time as either containing a humna or animal, which can support anit-poaching and conservation efforts. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By completing this tutorial, you will be able to:\n",
    "\n",
    "- Apply transfer learning concepts to thermal imagery classification\n",
    "- Implement CNN fine-tuning techniques using PyTorch\n",
    "- Understand the impact of hyperparameters on model accuracy\n",
    "- Evaluate model performance for conservation applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Environment Setup](#setup)\n",
    "3. [Data Preparation](#data)\n",
    "4. [Model Architecture](#model)\n",
    "5. [Training Process](#training)\n",
    "6. [Hyperparameter Exploration](#hyperparameters)\n",
    "7. [Evaluation](#evaluation)\n",
    "8. [Results and Discussion](#results)\n",
    "9. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## 1. Introduction\n",
    "\n",
    "Wildlife conservation increasingly relies on thermal imaging drones to monitor protected areas. Distinguishing humans (potential poachers) from animals presents unique challenges due to similar heat signatures. This tutorial applies transfer learning with pre-trained CNNs for this specialized classification task.\n",
    "\n",
    "Unlike existing tutorials that focus on standard RGB images, our approach addresses thermal imagery's unique characteristics while integrating systematic experiment tracking for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tutorial Source | Strengths | Limitations | Our Approach |\n",
    "|-----------------|-----------|-------------|--------------|\n",
    "| PyTorch Official | Comprehensive coverage of transfer learning | Uses standard RGB datasets | Adapts techniques for thermal imagery |\n",
    "| TorchVision Transfer Learning | Clear explanation of freezing layers | Limited hyperparameter exploration | Systematic hyperparameter optimization with MLflow |\n",
    "| Fast.ai | User-friendly high-level API | Less customization for specialized domains | Balance between accessibility and customization |\n",
    "| Keras Transfer Learning | Good visualization techniques | No experiment tracking | Integrated MLflow tracking for reproducibility |\n",
    "| Papers with Code Implementations | State-of-the-art approaches | Often complex and research-focused | Practical, application-focused approach |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 2. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed()\n",
    "\n",
    "# Define device as CPU explicitly\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## 3. Data Preparation\n",
    "Our dataset contains infrared drone imagery with annotations identifying humans (class 1) and animals (class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset metadata\n",
    "with open('birdsai_data/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"Dataset: {metadata['train_images']} training, {metadata['val_images']} validation, {metadata['test_images']} test images\")\n",
    "print(f\"Classes: {metadata['human_images']} humans, {metadata['animal_images']} animals\")\n",
    "\n",
    "# Load annotations\n",
    "train_annotations = pd.read_csv('birdsai_data/train/annotations.csv')\n",
    "val_annotations = pd.read_csv('birdsai_data/val/annotations.csv')\n",
    "test_annotations = pd.read_csv('birdsai_data/test/annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise a sample image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_sample(split='train', index=0):\n",
    "    \"\"\"Visualize a sample image with annotations\"\"\"\n",
    "    # Load annotations\n",
    "    if split == 'train':\n",
    "        annotations = train_annotations\n",
    "    elif split == 'val':\n",
    "        annotations = val_annotations\n",
    "    else:\n",
    "        annotations = test_annotations\n",
    "        \n",
    "    frame_number = annotations['frame_number'].unique()[index]\n",
    "    frame_annos = annotations[annotations['frame_number'] == frame_number]\n",
    "    \n",
    "    # Load image\n",
    "    img_path = f'birdsai_data/{split}/images/image_{int(frame_number):06d}.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot image with annotations\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for _, anno in frame_annos.iterrows():\n",
    "        x, y, w, h = int(anno[\"x\"]), int(anno[\"y\"]), int(anno[\"w\"]), int(anno[\"h\"])\n",
    "        class_id = int(anno[\"class\"])\n",
    "        color = 'green' if class_id == 1 else 'red'  # Green for humans, red for animals\n",
    "        \n",
    "        # Create rectangle\n",
    "        rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "    plt.title(f\"Sample from {split} set\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Show a sample\n",
    "visualise_sample('train', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfraredDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None):\n",
    "        \"\"\"Dataset for infrared images with human/animal annotations\"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load annotations\n",
    "        self.annotations = pd.read_csv(os.path.join(root_dir, split, 'annotations.csv'))\n",
    "        self.frame_numbers = self.annotations['frame_number'].unique()\n",
    "        \n",
    "        # Assign class to each image (1 if humans present, 0 if only animals)\n",
    "        self.image_classes = {}\n",
    "        for frame in self.frame_numbers:\n",
    "            frame_annos = self.annotations[self.annotations['frame_number'] == frame]\n",
    "            humans_present = (frame_annos['class'] == 1).any()\n",
    "            self.image_classes[frame] = 1 if humans_present else 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frame_numbers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        frame_number = self.frame_numbers[idx]\n",
    "        img_path = os.path.join(self.root_dir, self.split, 'images', f\"image_{int(frame_number):06d}.jpg\")\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.image_classes[frame_number]\n",
    "\n",
    "# Define transformations and create datasets\n",
    "def get_transforms(split):\n",
    "    \"\"\"Get appropriate transforms for training or evaluation\"\"\"\n",
    "    if split == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = InfraredDataset('birdsai_data', 'train', transform=get_transforms('train'))\n",
    "val_dataset = InfraredDataset('birdsai_data', 'val', transform=get_transforms('val'))\n",
    "test_dataset = InfraredDataset('birdsai_data', 'test', transform=get_transforms('test'))\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16  # Adjust based on your system\n",
    "num_workers = 0  # Adjust based on your system\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f\"Created dataloaders: {len(train_loader.dataset)} training, {len(val_loader.dataset)} validation, {len(test_loader.dataset)} test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 4. Model Architecture\n",
    "\n",
    "We leverage transfer learning using pre-trained ResNet18, adapting it for our binary classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=2, pretrained=True, freeze_layers=True):\n",
    "    \"\"\"Create a ResNet18 model for transfer learning\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes (default: 2)\n",
    "        pretrained: Whether to use pre-trained weights (default: True)\n",
    "        freeze_layers: Whether to freeze pre-trained layers (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        PyTorch model\n",
    "    \"\"\"\n",
    "    # Load pre-trained ResNet18\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    \n",
    "    # Freeze layers if specified\n",
    "    if freeze_layers:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Modify the final fully connected layer for our classification task\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instance\n",
    "model = create_model(num_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model architecture summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "## 5. Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=5, config_name=\"Default\"):\n",
    "    \"\"\"Train model and track metrics\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        optimizer: PyTorch optimizer\n",
    "        criterion: Loss function\n",
    "        num_epochs: Number of training epochs\n",
    "        config_name: Name of configuration for logging\n",
    "    \n",
    "    Returns:\n",
    "        Trained model and training history\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining configuration: {config_name}\")\n",
    "    print(f\"Optimizer: {optimizer.__class__.__name__}, Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "    # History for metrics\n",
    "    history = {\n",
    "        'train_loss': [], \n",
    "        'train_acc': [], \n",
    "        'val_loss': [], \n",
    "        'val_acc': [],\n",
    "        'config_name': config_name\n",
    "    }\n",
    "    \n",
    "    # Initial validation to get baseline performance\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    print(f\"Initial validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate epoch training metrics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(model.state_dict(), f\"models/resnet18_{config_name.replace(' ', '_').lower()}.pt\")\n",
    "    \n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for plotting learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(histories):\n",
    "    \"\"\"Plot learning curves for multiple training runs\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history in histories:\n",
    "        plt.plot(range(1, len(history['train_loss'])+1), \n",
    "                 history['train_loss'], \n",
    "                 marker='o', \n",
    "                 label=f\"{history['config_name']} (Train)\")\n",
    "        plt.plot(range(1, len(history['val_loss'])+1), \n",
    "                 history['val_loss'], \n",
    "                 marker='x', \n",
    "                 linestyle='--',\n",
    "                 label=f\"{history['config_name']} (Val)\")\n",
    "    \n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot training accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history in histories:\n",
    "        plt.plot(range(1, len(history['train_acc'])+1), \n",
    "                 history['train_acc'], \n",
    "                 marker='o', \n",
    "                 label=f\"{history['config_name']} (Train)\")\n",
    "        plt.plot(range(1, len(history['val_acc'])+1), \n",
    "                 history['val_acc'], \n",
    "                 marker='x', \n",
    "                 linestyle='--',\n",
    "                 label=f\"{history['config_name']} (Val)\")\n",
    "    \n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    os.makedirs('figures', exist_ok=True)\n",
    "    plt.savefig(\"figures/learning_curves_comparison.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion=None, class_names=[\"Animal\", \"Human\"], metrics_only=False):\n",
    "    \"\"\"\n",
    "    Evaluate model and compute metrics\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        data_loader: DataLoader for evaluation\n",
    "        criterion: Loss function (optional)\n",
    "        class_names: Class names for visualization\n",
    "        metrics_only: If True, return only loss and accuracy without visualizations\n",
    "        \n",
    "    Returns:\n",
    "        Metrics including loss and accuracy\n",
    "    \"\"\"\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Update metrics\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store for later analysis\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    avg_loss = total_loss / len(data_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # If only metrics requested, return now\n",
    "    if metrics_only:\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('figures', exist_ok=True)\n",
    "    plt.savefig(\"figures/confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    cr = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(cr)\n",
    "    \n",
    "    # Calculate PR curve and average precision (for human class)\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs[:, 1], pos_label=1)\n",
    "    ap = average_precision_score(all_labels, all_probs[:, 1])\n",
    "    \n",
    "    # Plot PR curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, marker='.', label=f'AP = {ap:.3f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve (Human Class)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figures/pr_curve.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(f\"\\nEvaluation Results:\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Average Precision (Human class): {ap:.4f}\")\n",
    "    \n",
    "    return avg_loss, accuracy, cm, ap\n",
    "\n",
    "def visualize_predictions(model, data_loader, num_samples=6):\n",
    "    \"\"\"Show model predictions on sample images\"\"\"\n",
    "    model.eval()\n",
    "    class_names = [\"Animal\", \"Human\"]\n",
    "    \n",
    "    # Get a batch of images\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images[:num_samples], labels[:num_samples]\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    images = images.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "    labels = labels.numpy()\n",
    "    probs = probs.cpu().numpy()\n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    for i in range(num_samples):\n",
    "        ax = fig.add_subplot(2, 3, i+1, xticks=[], yticks=[])\n",
    "        \n",
    "        # Convert normalized tensor to image\n",
    "        img = np.transpose(images[i], (1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        prediction_confidence = probs[i, preds[i]] * 100\n",
    "        \n",
    "        # Set title color based on correctness\n",
    "        title_color = \"green\" if preds[i] == labels[i] else \"red\"\n",
    "        \n",
    "        ax.set_title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[preds[i]]} ({prediction_confidence:.1f}%)\", \n",
    "                    color=title_color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    os.makedirs('figures', exist_ok=True)\n",
    "    plt.savefig(\"figures/sample_predictions.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hyperparameters\"></a>\n",
    "## 7. Hyperparameter Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_hyperparameters():\n",
    "    \"\"\"Run experiments with different hyperparameters for ResNet18\"\"\"\n",
    "    # Define configurations to try\n",
    "    configurations = [\n",
    "        {\n",
    "            \"name\": \"Baseline (Adam, LR=0.001, Frozen)\",\n",
    "            \"optimizer_class\": optim.Adam,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"freeze_layers\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Lower LR (Adam, LR=0.0001, Frozen)\",\n",
    "            \"optimizer_class\": optim.Adam,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"freeze_layers\": True,\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Unfrozen Layers (Adam, LR=0.0001)\",\n",
    "            \"optimizer_class\": optim.Adam,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"freeze_layers\": False,\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Common settings\n",
    "    num_epochs = 3  # Using fewer epochs for demonstration purposes\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Run each configuration and collect results\n",
    "    histories = []\n",
    "    test_results = []\n",
    "    \n",
    "    for config in configurations:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Starting training: {config['name']}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Create model with specified freezing\n",
    "        model = create_model(num_classes=2, freeze_layers=config['freeze_layers'])\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Create optimizer\n",
    "        optimizer = config['optimizer_class'](model.parameters(), lr=config['learning_rate'])\n",
    "        \n",
    "        # Train model\n",
    "        _, history = train_model(\n",
    "            model, train_loader, val_loader, \n",
    "            optimizer, criterion, \n",
    "            num_epochs=num_epochs, \n",
    "            config_name=config['name']\n",
    "        )\n",
    "        histories.append(history)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_loss, test_acc = evaluate_model(model, test_loader, criterion, metrics_only=True)\n",
    "        test_results.append({\n",
    "            \"config_name\": config['name'],\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc,\n",
    "            \"final_val_acc\": history['val_acc'][-1],\n",
    "            \"freeze_layers\": config['freeze_layers'],\n",
    "            \"learning_rate\": config['learning_rate'],\n",
    "            \"optimizer\": config['optimizer_class'].__name__\n",
    "        })\n",
    "        \n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plot_learning_curves(histories)\n",
    "    \n",
    "    # Create and display results table\n",
    "    results_df = pd.DataFrame(test_results)\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(results_df[[\"config_name\", \"final_val_acc\", \"test_acc\"]])\n",
    "    \n",
    "    # Plot test accuracy comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(results_df['config_name'], results_df['test_acc'], color='skyblue')\n",
    "    plt.xlabel('Configuration')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.title('Test Accuracy by Configuration')\n",
    "    plt.xticks(rotation=20, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                 bar.get_height() + 0.01, \n",
    "                 f'{bar.get_height():.4f}', \n",
    "                 ha='center')\n",
    "    \n",
    "    plt.savefig(\"figures/test_accuracy_comparison.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df, histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "## 8. Results and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_model(results_df):\n",
    "    \"\"\"Load and evaluate the best model based on validation accuracy\"\"\"\n",
    "    # Find the best configuration\n",
    "    best_config = results_df.loc[results_df['test_acc'].idxmax()]\n",
    "    print(f\"Best configuration: {best_config['config_name']}\")\n",
    "    print(f\"Test accuracy: {best_config['test_acc']:.4f}\")\n",
    "    \n",
    "    # Load the best model\n",
    "    model_path = f\"models/resnet18_{best_config['config_name'].replace(' ', '_').lower()}.pt\"\n",
    "    \n",
    "    # Create model with the same configuration\n",
    "    model = create_model(num_classes=2, freeze_layers=best_config['freeze_layers'])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Full evaluation\n",
    "    print(\"\\nFull evaluation of best model:\")\n",
    "    evaluate_model(model, test_loader)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    print(\"\\nVisualizing predictions:\")\n",
    "    visualize_predictions(model, test_loader)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Main workflow\n",
    "def main_workflow():\n",
    "    \"\"\"Run the complete workflow\"\"\"\n",
    "    # Explore hyperparameters\n",
    "    results_df, histories = explore_hyperparameters()\n",
    "    \n",
    "    # Evaluate best model\n",
    "    best_model = evaluate_best_model(results_df)\n",
    "    \n",
    "    # Return results for further analysis if needed\n",
    "    return results_df, histories, best_model\n",
    "\n",
    "# Uncomment to run the complete workflow\n",
    "# results, histories, best_model = main_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, histories, best_model = main_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
