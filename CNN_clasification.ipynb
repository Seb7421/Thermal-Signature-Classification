{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: center;\">Fine-Tuning a Convolutional Neural Network for Infrared Drone Image Classification in Wildlife Conservation</p>\n",
    "\n",
    "<p style=\"text-align: center;\">Abstract: </p>\n",
    "<p style=\"text-align: center;\"> This tutorial demonstrates how to effectively fine tune and evaluate a CNN model using the birdsai dataset of night time infrared images from drones in Souther Africa. The tutorial starts with how to best set up the data for the fine tuning, then the process of fine-tuning and evaluating the CNN model. The resulting model is one that can be used to classify frames captured by drones at night time as either containing a humna or animal, which can support anit-poaching and conservation efforts. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By completing this tutorial, you will be able to:\n",
    "\n",
    "- Apply transfer learning concepts to thermal imagery classification\n",
    "- Implement CNN fine-tuning techniques using PyTorch\n",
    "- Understand the impact of hyperparameters on model accuracy\n",
    "- Evaluate model performance for conservation applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Environment Setup](#setup)\n",
    "3. [Data Preparation](#data)\n",
    "4. [Model Architecture](#model)\n",
    "5. [Training Process](#training)\n",
    "6. [Hyperparameter Exploration](#hyperparameters)\n",
    "7. [Evaluation](#evaluation)\n",
    "8. [Results and Discussion](#results)\n",
    "9. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## 1. Introduction\n",
    "\n",
    "Wildlife conservation increasingly relies on thermal imaging drones to monitor protected areas. Distinguishing humans (potential poachers) from animals presents unique challenges due to similar heat signatures. This tutorial applies transfer learning with pre-trained CNNs for this specialized classification task.\n",
    "\n",
    "Unlike existing tutorials that focus on standard RGB images, our approach addresses thermal imagery's unique characteristics while integrating systematic experiment tracking for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 2. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed()\n",
    "\n",
    "\n",
    "# Define device as CPU explicitly\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## 3. Class Distribution Overview\n",
    "Our dataset contains infrared drone imagery with annotations identifying humans (class 1) and animals (class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('birdsai_data/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Load annotations to analyze class distribution by split\n",
    "train_annotations = pd.read_csv('birdsai_data/train/annotations.csv')\n",
    "val_annotations = pd.read_csv('birdsai_data/val/annotations.csv')\n",
    "test_annotations = pd.read_csv('birdsai_data/test/annotations.csv')\n",
    "\n",
    "def count_classes(split_name, annotations):\n",
    "    \"\"\"Count human and animal images in a dataset split\"\"\"\n",
    "    unique_frames = annotations['frame_number'].unique()\n",
    "    human_frames = 0\n",
    "    animal_frames = 0\n",
    "    \n",
    "    for frame in unique_frames:\n",
    "        frame_annos = annotations[annotations['frame_number'] == frame]\n",
    "        if (frame_annos['class'] == 1).any():  # If any human annotation\n",
    "            human_frames += 1\n",
    "        else:\n",
    "            animal_frames += 1\n",
    "    \n",
    "    total_frames = human_frames + animal_frames\n",
    "    print(f\"{split_name} set: {human_frames} humans ({human_frames/total_frames:.1%}), \"\n",
    "          f\"{animal_frames} animals ({animal_frames/total_frames:.1%})\")\n",
    "    \n",
    "    return human_frames, animal_frames\n",
    "\n",
    "# Print class distribution for each split\n",
    "print(\"Class distribution across dataset splits:\")\n",
    "train_humans, train_animals = count_classes('Training', train_annotations)\n",
    "val_humans, val_animals = count_classes('Validation', val_annotations)\n",
    "test_humans, test_animals = count_classes('Test', test_annotations)\n",
    "\n",
    "# Calculate class weights for training\n",
    "train_total = train_humans + train_animals\n",
    "class_weights = torch.FloatTensor([\n",
    "    train_total / (2 * train_animals),  # Weight for animals \n",
    "    train_total / (2 * train_humans)    # Weight for humans\n",
    "])\n",
    "print(f\"\\nClass weights to balance training: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "We create a dataset class to load our thermal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfraredDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None):\n",
    "        \"\"\"Dataset for infrared images with human/animal annotations\"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load annotations\n",
    "        self.annotations = pd.read_csv(os.path.join(root_dir, split, 'annotations.csv'))\n",
    "        self.frame_numbers = self.annotations['frame_number'].unique()\n",
    "        \n",
    "        # Assign class to each image (1 if humans present, 0 if only animals)\n",
    "        self.image_classes = {}\n",
    "        for frame in self.frame_numbers:\n",
    "            frame_annos = self.annotations[self.annotations['frame_number'] == frame]\n",
    "            humans_present = (frame_annos['class'] == 1).any()\n",
    "            self.image_classes[frame] = 1 if humans_present else 0\n",
    "        \n",
    "        # Count classes\n",
    "        classes = [self.image_classes[frame] for frame in self.frame_numbers]\n",
    "        self.human_count = sum(classes)\n",
    "        self.animal_count = len(classes) - self.human_count\n",
    "        print(f\"{split} set: {self.human_count} humans, {self.animal_count} animals\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frame_numbers)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        frame_number = self.frame_numbers[idx]\n",
    "        img_path = os.path.join(self.root_dir, self.split, 'images', f\"image_{int(frame_number):06d}.jpg\")\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.image_classes[frame_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the image transformations we'll use. These transformations resize the images, apply light data augmentation during training, and normalize the pixel values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(split):\n",
    "    \"\"\"Get appropriate transforms for training or evaluation\"\"\"\n",
    "    if split == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our dataset and dataloader objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = InfraredDataset('birdsai_data', 'train', transform=get_transforms('train'))\n",
    "val_dataset = InfraredDataset('birdsai_data', 'val', transform=get_transforms('val'))\n",
    "test_dataset = InfraredDataset('birdsai_data', 'test', transform=get_transforms('test'))\n",
    "\n",
    "# Calculate class weights to handle any imbalance\n",
    "train_counts = [train_dataset.animal_count, train_dataset.human_count]\n",
    "class_weights = torch.FloatTensor([\n",
    "    sum(train_counts) / (len(train_counts) * count) for count in train_counts\n",
    "])\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Created dataloaders with batch size {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the MobileNetV3-Small Model\n",
    "\n",
    "MobileNetV3-Small is designed for efficiency while maintaining good performance. It uses inverted residuals and linear bottlenecks to reduce computation while preserving accuracy. Let's create our model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetv3_model(num_classes=2, pretrained=True):\n",
    "    \"\"\"Create a MobileNetV3-Small model for thermal imagery classification\"\"\"\n",
    "    # Load pre-trained MobileNetV3-Small\n",
    "    model = models.mobilenet_v3_small(pretrained=pretrained)\n",
    "    \n",
    "    # Replace the classifier for our binary classification task\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(576, 256),  # 576 is the output dimension of MobileNetV3-Small's features\n",
    "        nn.Hardswish(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model and move to appropriate device\n",
    "model = create_mobilenetv3_model()\n",
    "model = model.to(device)\n",
    "\n",
    "# Display model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"MobileNetV3-Small model created:\")\n",
    "print(f\"• Total parameters: {total_params:,}\")\n",
    "print(f\"• Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Freezing and Unfreezing Model Layers\n",
    "\n",
    "When fine-tuning a pre-trained model, we often start by freezing most of the network. This means only training the classification head initially, then gradually unfreezing more layers. Let's see how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model_features(model):\n",
    "    \"\"\"Freeze all features, leaving only classifier trainable\"\"\"\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Verify what's frozen vs trainable\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    \n",
    "    print(f\"After freezing features:\")\n",
    "    print(f\"• Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"• Frozen parameters: {frozen_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Freeze the model features\n",
    "model = freeze_model_features(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how to selectively unfreeze layers when we want to fine-tune deeper parts of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectively unfreeze the last few layers\n",
    "def unfreeze_last_layers(model, num_layers=3):\n",
    "    \"\"\"Unfreeze the last n layers of the feature extractor\"\"\"\n",
    "    # MobileNetV3's features are sequential, so we can count from the end\n",
    "    feature_length = len(model.features)\n",
    "    \n",
    "    # Keep everything frozen\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze the last n layers\n",
    "    for i in range(feature_length - num_layers, feature_length):\n",
    "        for param in model.features[i].parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Verify what's frozen vs trainable\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "    \n",
    "    print(f\"After unfreezing last {num_layers} layers:\")\n",
    "    print(f\"• Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"• Frozen parameters: {frozen_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Unfreeze the last 3 layers\n",
    "model = unfreeze_last_layers(model, num_layers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 7. Training with Hyperparameter Tuning\n",
    "\n",
    "Let's create a simple training function that will allow us to monitor model performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, val_loader, optimizer, criterion):\n",
    "    \"\"\"Train for one epoch and evaluate\"\"\"\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average training metrics\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    return avg_train_loss, train_acc, avg_val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how changing a key hyperparameter (learning rate) affects training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try two different learning rates and compare\n",
    "learning_rates = [0.01, 0.001]\n",
    "num_epochs = 5\n",
    "\n",
    "# Dictionary to store results for comparison\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "    \n",
    "    # Reset model weights for fair comparison\n",
    "    model = create_mobilenetv3_model()\n",
    "    model = unfreeze_last_layers(model, num_layers=3)  # Use our unfreezing strategy\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create optimizer with current learning rate\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    # Create loss function with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    # Track metrics\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # Train for several epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc, val_loss, val_acc = train_epoch(\n",
    "            model, train_loader, val_loader, optimizer, criterion\n",
    "        )\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Store results for this learning rate\n",
    "    results[lr] = {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results to see the impact of different learning rates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation accuracy for different learning rates\n",
    "plt.figure(figsize=(10, 5))\n",
    "for lr, metrics in results.items():\n",
    "    plt.plot(range(1, num_epochs+1), \n",
    "             [acc * 100 for acc in metrics['val_accs']],  # Convert to percentage\n",
    "             marker='o', \n",
    "             label=f'LR = {lr}')\n",
    "\n",
    "plt.title('Validation Accuracy by Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(\"learning_rate_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# Find the best learning rate\n",
    "best_lr = max(results.keys(), key=lambda lr: max(results[lr]['val_accs']))\n",
    "print(f\"Best learning rate: {best_lr} (max validation accuracy: {max(results[best_lr]['val_accs']):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training with the Best Hyperparameters\n",
    "\n",
    "Now that we've identified the optimal hyperparameters, let's train a model with those settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_best_parameters(num_epochs=10):\n",
    "    \"\"\"Train a model with the best hyperparameters we found\"\"\"\n",
    "    print(\"\\nTraining final model with optimal hyperparameters...\")\n",
    "    \n",
    "    # Create fresh model\n",
    "    model = create_mobilenetv3_model()\n",
    "    model = unfreeze_last_layers(model, num_layers=3)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Use the best learning rate we found\n",
    "    best_lr = 0.001  # This should be your best learning rate from the experiment\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=best_lr)\n",
    "    \n",
    "    # Create loss function with class weights\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    # Train for more epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        train_loss, train_acc, val_loss, val_acc = train_epoch(\n",
    "            model, train_loader, val_loader, optimizer, criterion\n",
    "        )\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, len(train_accs)+1), [acc * 100 for acc in train_accs], \n",
    "             marker='o', label='Train Accuracy')\n",
    "    plt.plot(range(1, len(val_accs)+1), [acc * 100 for acc in val_accs], \n",
    "             marker='o', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(\"training_curve.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(model.state_dict(), \"models/mobilenetv3_small_optimal.pt\")\n",
    "    \n",
    "    return model, {'train_losses': train_losses, 'train_accs': train_accs, \n",
    "                  'val_losses': val_losses, 'val_accs': val_accs}\n",
    "\n",
    "# Train with best parameters\n",
    "final_model, final_metrics = train_with_best_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluating the Model on Test Data\n",
    "\n",
    "Finally, let's evaluate our trained model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate model on test set and show confusion matrix\"\"\"\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f} ({correct}/{total})\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Animal\", \"Human\"], yticklabels=[\"Animal\", \"Human\"])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    cr = classification_report(all_labels, all_preds, target_names=[\"Animal\", \"Human\"])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(cr)\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# Evaluate final model\n",
    "test_accuracy, confusion_mat = evaluate_model(final_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the model's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_loader, num_samples=6):\n",
    "    \"\"\"Show model predictions on sample images\"\"\"\n",
    "    model.eval()\n",
    "    class_names = [\"Animal\", \"Human\"]\n",
    "    \n",
    "    # Get a batch of images\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images[:num_samples].to(device), labels[:num_samples]\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    images = images.cpu()\n",
    "    preds = preds.cpu().numpy()\n",
    "    labels = labels.numpy()\n",
    "    probs = probs.cpu().numpy()\n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    for i in range(num_samples):\n",
    "        ax = fig.add_subplot(2, 3, i+1, xticks=[], yticks=[])\n",
    "        \n",
    "        # Convert normalized tensor to image\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        prediction_confidence = probs[i, preds[i]] * 100\n",
    "        \n",
    "        # Set title color based on correctness\n",
    "        title_color = \"green\" if preds[i] == labels[i] else \"red\"\n",
    "        \n",
    "        ax.set_title(f\"True: {class_names[labels[i]]}\\nPred: {class_names[preds[i]]} ({prediction_confidence:.1f}%)\", \n",
    "                    color=title_color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"sample_predictions.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(final_model, test_loader)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nSummary of Key Tutorial Insights:\")\n",
    "print(\"1. MobileNetV3-Small is ideal for drone-based wildlife conservation applications\")\n",
    "print(\"2. Layer unfreezing strategy significantly affects training efficiency\")\n",
    "print(\"3. Learning rate is a critical hyperparameter for model performance\")\n",
    "print(f\"4. Our model achieved {test_accuracy:.2%} accuracy on the test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
