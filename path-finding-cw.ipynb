{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900d18b3-3709-473d-9887-4c0e33294906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "import time\n",
    "import motors\n",
    "import zed\n",
    "#define the thread function\n",
    "def thread_function():\n",
    "    #Let computer relax for 1ms\n",
    "    time.sleep(0.001)\n",
    "\n",
    "\n",
    "#link the thread with the target function\n",
    "x = threading.Thread(target = thread_function)\n",
    "x.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2249bc72-e362-4db3-ac69-b74f5defacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zed import Camera \n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "import threading\n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a6052ed-e555-4a10-aeeb-226b14e124a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85aed1b6ee5345a8bb938847fe236ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='100%'), Image(value=b'', format='jpeg', width='100%'), Iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from zed import Camera            # Import the ZED camera interface\n",
    "import traitlets\n",
    "\n",
    "# --- Utility Function ---\n",
    "def bgr8_to_jpeg(image):\n",
    "    \"\"\"Convert a BGR image (numpy array) to JPEG-encoded bytes.\"\"\"\n",
    "    return bytes(cv2.imencode('.jpg', image)[1])\n",
    "\n",
    "# --- Custom PID Controller ---\n",
    "class PID:\n",
    "    def __init__(self, Kp, Ki, Kd, setpoint=0, sample_time=0.01, output_limits=(-100, 100)):\n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.Kd = Kd\n",
    "        self.setpoint = setpoint\n",
    "        self.sample_time = sample_time\n",
    "        self.output_limits = output_limits\n",
    "        self._last_time = time.time()\n",
    "        self._last_error = 0.0\n",
    "        self._integral = 0.0\n",
    "\n",
    "    def update(self, measurement):\n",
    "        now = time.time()\n",
    "        dt = now - self._last_time\n",
    "        if dt < self.sample_time:\n",
    "            return None  # Not enough time has elapsed for an update.\n",
    "        error = self.setpoint - measurement\n",
    "        self._integral += error * dt\n",
    "        derivative = (error - self._last_error) / dt if dt > 0 else 0.0\n",
    "        output = (self.Kp * error) + (self.Ki * self._integral) + (self.Kd * derivative)\n",
    "        lower, upper = self.output_limits\n",
    "        if lower is not None:\n",
    "            output = max(lower, output)\n",
    "        if upper is not None:\n",
    "            output = min(upper, output)\n",
    "        self._last_error = error\n",
    "        self._last_time = now\n",
    "        return output\n",
    "\n",
    "# --- Global Objects & Parameters ---\n",
    "robot = motors.MotorsYukon(mecanum=True)  # Instantiate your motor controller.\n",
    "pid_controller = PID(Kp=0.1, Ki=0.01, Kd=0.05, setpoint=0, output_limits=(-100, 100))\n",
    "base_speed = 0.3          # Base forward speed.\n",
    "error_threshold = 100      # Pixel error threshold for going straight.\n",
    "\n",
    "# --- Set Up the ZED Camera and Display Widgets ---\n",
    "camera = Camera.instance()  # Create a singleton camera instance.\n",
    "camera.start()              # Start capturing images.\n",
    "\n",
    "# Create ipywidgets for displaying the color and depth images.\n",
    "display_color = widgets.Image(format='jpeg', width='100%')\n",
    "display_depth = widgets.Image(format='jpeg', width='100%')\n",
    "display_mask  = widgets.Image(format='jpeg', width='320px')\n",
    "layout = widgets.Layout(width='100%')\n",
    "sidebyside = widgets.HBox([display_color, display_depth, display_mask], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "# --- Process Callback Function ---\n",
    "def process(change):\n",
    "    \"\"\"\n",
    "    This callback is invoked whenever a new color frame is available.\n",
    "    It processes the frame to detect a yellow rope and computes motor actions.\n",
    "    \"\"\"\n",
    "    frame = change['new']\n",
    "    if frame is None:\n",
    "        return\n",
    "\n",
    "    # Crop the image to focus on the ground (bottom 50% of the frame)\n",
    "    height, width = frame.shape[:2]\n",
    "    crop_ratio = 2 # Adjust this ratio to keep more or less of the bottom portion.\n",
    "    roi = frame[int(height * crop_ratio):, :] \n",
    "\n",
    "    \n",
    "    # For visualization, you can also draw the ROI rectangle on the original frame.\n",
    "    cv2.rectangle(frame, (0, int(height * crop_ratio)), (width, height), (0, 255, 0), 2)\n",
    "\n",
    "    # Copy the frame for processing.\n",
    "    proc_frame = roi.copy()\n",
    "\n",
    "    # Convert BGR to HSV and create a mask for the yellow rope.\n",
    "    hsv = cv2.cvtColor(proc_frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_yellow = np.array([10, 80, 80])\n",
    "    upper_yellow = np.array([40, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Clean up the mask using morphological operations.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "    # Compute the moments of the mask to locate the rope's centroid.\n",
    "    M = cv2.moments(mask)\n",
    "    if M['m00'] > 0:\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        # Visualize the centroid.\n",
    "        cv2.circle(proc_frame, (cx, cy), 5, (255, 0, 0), -1)\n",
    "\n",
    "        # Calculate horizontal error (difference between image center and centroid).\n",
    "        frame_center = proc_frame.shape[1] // 2\n",
    "        error = frame_center - cx\n",
    "\n",
    "        # Update the PID controller.\n",
    "        control_output = pid_controller.update(error)\n",
    "        if control_output is not None:\n",
    "            # If error is small, move forward.\n",
    "            if abs(error) < error_threshold:\n",
    "                robot.forward(speed=base_speed)\n",
    "                print(\"Moving Forward\")\n",
    "            elif error > 0:\n",
    "                # Rope is left of center; turn left.\n",
    "                turn_speed = min(0.6, base_speed + (abs(control_output) / 100.0) * 0.3)\n",
    "                robot.right(speed=turn_speed)\n",
    "                print(f\"Turning Left | Error: {error}, Turn Speed: {turn_speed}\")\n",
    "            else:\n",
    "                # Rope is right of center; turn right.\n",
    "                turn_speed = min(0.6, base_speed + (abs(control_output) / 100.0) * 0.3)\n",
    "                robot.left(speed=turn_speed)\n",
    "                print(f\"Turning Right | Error: {error}, Turn Speed: {turn_speed}\")\n",
    "    else:\n",
    "        # If the rope is not detected, stop the robot.\n",
    "        robot.stop()\n",
    "        print(\"Rope not detected. Stopping.\")\n",
    "\n",
    "    # Update the widget displays with resized images.\n",
    "    display_color.value = bgr8_to_jpeg(cv2.resize(proc_frame, (320, 240)))\n",
    "    display_depth.value = bgr8_to_jpeg(cv2.resize(camera.depth_value, (320, 240)))\n",
    "    # Convert the mask (grayscale) to BGR for proper JPEG encoding and display.\n",
    "    mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    display_mask.value = bgr8_to_jpeg(cv2.resize(mask_bgr, (320, 240)))\n",
    "\n",
    "# --- Start Observing the Camera's Color Frame ---\n",
    "camera.observe(process, names='color_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae5175-64ba-4f34-94e8-20df3a194130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4ed23-bca2-4ca2-91de-7e677d1712b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
